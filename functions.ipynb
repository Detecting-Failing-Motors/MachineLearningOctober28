{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np \n",
    "from scipy.signal import welch\n",
    "from detect_peaks import detect_peaks\n",
    "from scipy.stats import kurtosis\n",
    "from scipy.stats import skew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Classifiers\n",
    "#https://scikit-learn.org/stable/supervised_learning.html#supervised-learning\n",
    "#Linear Models\n",
    "from sklearn.linear_model import ARDRegression\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.linear_model import ElasticNetCV\n",
    "from sklearn.linear_model import Hinge\n",
    "from sklearn.linear_model import Huber\n",
    "from sklearn.linear_model import HuberRegressor\n",
    "from sklearn.linear_model import Lars\n",
    "from sklearn.linear_model import LarsCV\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.linear_model import LassoLars\n",
    "from sklearn.linear_model import LassoLarsCV\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Log\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.linear_model import ModifiedHuber\n",
    "from sklearn.linear_model import MultiTaskElasticNet\n",
    "from sklearn.linear_model import MultiTaskElasticNetCV\n",
    "from sklearn.linear_model import MultiTaskLasso\n",
    "from sklearn.linear_model import MultiTaskLassoCV\n",
    "from sklearn.linear_model import OrthogonalMatchingPursuit\n",
    "from sklearn.linear_model import OrthogonalMatchingPursuitCV\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "from sklearn.linear_model import PassiveAggressiveRegressor\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import RANSACRegressor\n",
    "#from sklearn.linear_model import RandomizedLasso\n",
    "#from sklearn.linear_model import RandomizedLogisticRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.linear_model import SquaredLoss\n",
    "from sklearn.linear_model import TheilSenRegressor\n",
    "\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Linear and Quadratic Discriminant Analysis\n",
    "from sklearn.discriminant_analysis import BaseEstimator\n",
    "from sklearn.discriminant_analysis import ClassifierMixin\n",
    "from sklearn.discriminant_analysis import LinearClassifierMixin\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import StandardScaler\n",
    "from sklearn.discriminant_analysis import TransformerMixin\n",
    "\n",
    "#Kernel Ridge Regression\n",
    "from sklearn.kernel_ridge import BaseEstimator\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.kernel_ridge import RegressorMixin\n",
    "\n",
    "#Support Vector Machines\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import LinearSVR\n",
    "from sklearn.svm import NuSVC\n",
    "from sklearn.svm import NuSVR\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "#Stochastic Gradient Descent\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "\n",
    "#Nearest Neighbors\n",
    "from sklearn.neighbors import BallTree\n",
    "from sklearn.neighbors import DistanceMetric\n",
    "from sklearn.neighbors import KDTree\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.neighbors import KernelDensity\n",
    "#from sklearn.neighbors import LSHForest\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.neighbors import NearestCentroid\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.neighbors import RadiusNeighborsClassifier\n",
    "from sklearn.neighbors import RadiusNeighborsRegressor\n",
    "\n",
    "#Gaussian Processes\n",
    "#from sklearn.gaussian_process import GaussianProcess\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "\n",
    "#Cross Decomposition\n",
    "from sklearn.cross_decomposition import CCA\n",
    "from sklearn.cross_decomposition import PLSCanonical\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from sklearn.cross_decomposition import PLSSVD\n",
    "\n",
    "\n",
    "#Naive Bayes\n",
    "from sklearn.naive_bayes import ABCMeta\n",
    "from sklearn.naive_bayes import BaseDiscreteNB\n",
    "from sklearn.naive_bayes import BaseEstimator\n",
    "from sklearn.naive_bayes import BaseNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import ClassifierMixin\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import LabelBinarizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "#Decision Trees\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.tree import ExtraTreeClassifier\n",
    "\n",
    "#Ensemble Methods\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.ensemble import BaseEnsemble\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import RandomTreesEmbedding\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "\n",
    "#Multiclass and multilabel algorithms\n",
    "from sklearn.multiclass import BaseEstimator\n",
    "from sklearn.multiclass import ClassifierMixin\n",
    "from sklearn.multiclass import LabelBinarizer\n",
    "from sklearn.multiclass import MetaEstimatorMixin\n",
    "from sklearn.multiclass import OneVsOneClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.multiclass import OutputCodeClassifier\n",
    "from sklearn.multiclass import Parallel\n",
    "from sklearn.multioutput import ABCMeta\n",
    "from sklearn.multioutput import BaseEstimator\n",
    "from sklearn.multioutput import ClassifierChain\n",
    "from sklearn.multioutput import ClassifierMixin\n",
    "from sklearn.multioutput import MetaEstimatorMixin\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.multioutput import MultiOutputEstimator\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.multioutput import Parallel\n",
    "from sklearn.multioutput import RegressorMixin\n",
    "\n",
    "#Semi-Suportvised\n",
    "from sklearn.semi_supervised import LabelPropagation\n",
    "from sklearn.semi_supervised import LabelSpreading\n",
    "from sklearn.semi_supervised import label_propagation\n",
    "\n",
    "#Isotonic Regression\n",
    "from sklearn.isotonic import BaseEstimator\n",
    "from sklearn.isotonic import IsotonicRegression\n",
    "from sklearn.isotonic import RegressorMixin\n",
    "from sklearn.isotonic import TransformerMixin\n",
    "\n",
    "# Neural network models (supervised)\n",
    "from sklearn.neural_network import BernoulliRBM\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neural_network import MLPRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature Selection\n",
    "from sklearn.feature_selection import GenericUnivariateSelect\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.feature_selection import SelectFdr\n",
    "from sklearn.feature_selection import SelectFpr\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.feature_selection import SelectFwe\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import SelectPercentile\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from pandas.plotting import scatter_matrix\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BearingInfomation(UserInput):\n",
    "    n = UserInput['n']\n",
    "    N = UserInput['N']\n",
    "    Bd = UserInput['Bd']\n",
    "    Pd = UserInput['Pd']\n",
    "    phi = UserInput['Phi']\n",
    "    xx = Bd/Pd*np.cos(phi)\n",
    "    BPFI = (N/2)*(1 + xx)*n\n",
    "    BPFO = (N/2)*(1 - xx)*n\n",
    "    BSF = (Pd/(2*Bd))*(1-(xx)**2)*n\n",
    "    FTF= (1/2)*(1 - xx)*n\n",
    "    x = {\n",
    "        \"BPFI\": BPFI,\n",
    "        \"BPFO\": BPFO,\n",
    "        \"BSF\":  BSF,\n",
    "        \"FTF\":  FTF\n",
    "    }\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RemoveDCOffset(UserInput):\n",
    "    UserInput[\"Signal Data of Interest\"] = UserInput[\"Signal Data of Interest\"] - np.mean(UserInput[\"Signal Data of Interest\"])\n",
    "    return UserInput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FourierTransform(UserInput):\n",
    "    #Fast Fourier Transform\n",
    "    sig = UserInput['Signal Data of Interest']\n",
    "    NumberOfSamples = UserInput['Number of Samples']\n",
    "    Tmax = UserInput['Time of Sampling']\n",
    "    frq = np.arange(NumberOfSamples)/(Tmax)# two sides frequency range\n",
    "    frq = frq[range(int(NumberOfSamples/(2)))] # one side frequency range\n",
    "    Y = abs(np.fft.fft(sig))/NumberOfSamples # fft computing and normalization\n",
    "    Y = Y[range(int(NumberOfSamples/2))]\n",
    "    #End fft\n",
    "    x = {\n",
    "        \"Frequency\":frq,\n",
    "        \"Freq. Amp.\": Y\n",
    "        }\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_psd_values(UserInput):\n",
    "    sig = UserInput['Signal Data of Interest']\n",
    "    SamplingFrequency = UserInput['Sampling Frequency']\n",
    "    frq, psd_values = welch(sig, fs=SamplingFrequency)\n",
    "    x = {\n",
    "        \"Frequency\":frq,\n",
    "        \"PSD\": psd_values\n",
    "        }\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def autocorr(x):\n",
    "    #Subfunction of get_autocorr_values\n",
    "    result = np.correlate(x, x, mode='full')\n",
    "    return result[len(result)//2:]\n",
    "\n",
    "def get_autocorr_values(UserInput):\n",
    "    sig = UserInput['Signal Data of Interest']\n",
    "    Tmax = UserInput['Time of Sampling']\n",
    "    N = UserInput['Number of Samples']\n",
    "    autocorr_values = autocorr(sig)\n",
    "    x_values = np.array([Tmax * jj for jj in range(0, N)])\n",
    "    x = {\n",
    "        \"X Values\":x_values,\n",
    "        \"Autocorr Values\": autocorr_values\n",
    "        }\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TimeDomainInformation(UserInput):\n",
    "    sig = UserInput['Signal Data of Interest']\n",
    "    x = {\n",
    "        \"RMS\": np.mean(sig**2),\n",
    "        \"STD\": np.std(sig),\n",
    "        \"Mean\": np.mean(sig),\n",
    "        \"Max\": np.max(sig),\n",
    "        \"Min\": np.min(sig),\n",
    "        \"Peak-to-Peak\": (np.max(sig) - np.min(sig)),\n",
    "        \"Max ABS\": np.max(abs(sig)),\n",
    "        \"Kurtosis\": kurtosis(sig),\n",
    "        \"Skew\": skew(sig),\n",
    "    }\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetSortedPeak(X,Y):\n",
    "    #SubFunction for FrequencyDomainInformation\n",
    "    max_peak_height = 0.1 * np.nanmax(Y)\n",
    "    threshold = 0.05 * np.nanmax(Y)\n",
    "    #Get indices of peak\n",
    "    peak = detect_peaks(Y,edge = 'rising',mph = max_peak_height, mpd = 2, threshold = threshold )\n",
    "    \n",
    "    m = []\n",
    "    mm = []\n",
    "    for i in peak:\n",
    "        m.append(Y[i]) \n",
    "        mm.append(X[i])\n",
    "\n",
    "    mmm = np.argsort(m)\n",
    "    n = []\n",
    "    nn = []\n",
    "    for i in mmm:\n",
    "        n.append(m[i])\n",
    "        nn.append(mm[i])\n",
    "\n",
    "    n  = n[::-1]\n",
    "    nn = nn[::-1]\n",
    "\n",
    "    return n, nn\n",
    "\n",
    "def FrequencyDomainInformation(UserInput):\n",
    "    x1 = FourierTransform(UserInput)\n",
    "    x2 = get_psd_values(UserInput)\n",
    "    x3 = get_autocorr_values(UserInput)\n",
    "    FTamp,FTfreq = GetSortedPeak(x1['Frequency'],x1['Freq. Amp.'])\n",
    "    PSDamp,PSDfreq = GetSortedPeak(x2['Frequency'],x2['PSD'])\n",
    "    Cor,CorTime = GetSortedPeak(x3['X Values'],x3['Autocorr Values'])\n",
    "\n",
    "    while len(FTamp) <= 5:\n",
    "        FTamp.append(['-999'])\n",
    "    while len(FTfreq) <= 5:\n",
    "        FTfreq.append(['-999'])\n",
    "    while len(PSDamp) <= 5:\n",
    "        PSDamp.append(['-999'])\n",
    "    while len(PSDfreq) <= 5:\n",
    "        PSDfreq.append(['-999'])\n",
    "    while len(Cor) <= 5:\n",
    "        Cor.append(['-999'])\n",
    "    while len(CorTime) <= 5:\n",
    "        CorTime.append(['-999'])\n",
    "    \n",
    "    x = {\n",
    "        \"FFT Frq @ Peak 1\": FTfreq[0],\n",
    "        \"FFT Frq @ Peak 2\": FTfreq[1],\n",
    "        \"FFT Frq @ Peak 3\": FTfreq[2],\n",
    "        \"FFT Frq @ Peak 4\": FTfreq[3],\n",
    "        \"FFT Frq @ Peak 5\": FTfreq[4],\n",
    "        \"FFT Amp @ Peak 1\": FTamp[0],\n",
    "        \"FFT Amp @ Peak 2\": FTamp[1],\n",
    "        \"FFT Amp @ Peak 3\": FTamp[2],\n",
    "        \"FFT Amp @ Peak 4\": FTamp[3],\n",
    "        \"FFT Amp @ Peak 5\": FTamp[4],\n",
    "        \"PSD Frq @ Peak 1\": PSDfreq[0],\n",
    "        \"PSD Frq @ Peak 2\": PSDfreq[1],\n",
    "        \"PSD Frq @ Peak 3\": PSDfreq[2],\n",
    "        \"PSD Frq @ Peak 4\": PSDfreq[3],\n",
    "        \"PSD Frq @ Peak 5\": PSDfreq[4],\n",
    "        \"PSD Amp @ Peak 1\": PSDamp[0],\n",
    "        \"PSD Amp @ Peak 2\": PSDamp[1],\n",
    "        \"PSD Amp @ Peak 3\": PSDamp[2],\n",
    "        \"PSD Amp @ Peak 4\": PSDamp[3],\n",
    "        \"PSD Amp @ Peak 5\": PSDamp[4],\n",
    "        \"Autocorrelate Time @ Peak 1\": CorTime[0],\n",
    "        \"Autocorrelate Time @ Peak 2\": CorTime[1],\n",
    "        \"Autocorrelate Time @ Peak 3\": CorTime[2],\n",
    "        \"Autocorrelate Time @ Peak 4\": CorTime[3],\n",
    "        \"Autocorrelate Time @ Peak 5\": CorTime[4],\n",
    "        \"Autocorrelate @ Peak 1\": Cor[0],\n",
    "        \"Autocorrelate @ Peak 2\": Cor[1],\n",
    "        \"Autocorrelate @ Peak 3\": Cor[2],\n",
    "        \"Autocorrelate @ Peak 4\": Cor[3],\n",
    "        \"Autocorrelate @ Peak 5\": Cor[4]\n",
    "    }\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "http://mkalikatzarakis.eu/wp-content/uploads/2018/12/IMS_dset.html\n",
    "Previous work done on this dataset states that seven different states of health were observed:\n",
    "\n",
    "Early (initial run-in of the bearings)\n",
    "Normal\n",
    "Suspect (the health seems to be deteriorating)\n",
    "Imminent failure (for bearings 1 and 2, which didnâ€™t actually fail, but were severely worn out)\n",
    "Inner race failure (bearing 3)\n",
    "Rolling element failure (bearing 4)\n",
    "Stage 2 failure (bearing 4)\n",
    "For the first test (the one we are working on), the following labels have been proposed per file:\n",
    "\n",
    "Bearing 1\n",
    "early: 2003.10.22.12.06.24 - 2013.10.23.09.14.13\n",
    "suspect: 2013.10.23.09.24.13 - 2003.11.08.12.11.44 (bearing 1 was in suspicious health from the beginning, but showed some self-healing effects)\n",
    "normal: 2003.11.08.12.21.44 - 2003.11.19.21.06.07\n",
    "suspect: 2003.11.19.21.16.07 - 2003.11.24.20.47.32\n",
    "imminent failure: 2003.11.24.20.57.32 - 2003.11.25.23.39.56\n",
    "\n",
    "Bearing 2\n",
    "early: 2003.10.22.12.06.24 - 2003.11.01.21.41.44\n",
    "normal: 2003.11.01.21.51.44 - 2003.11.24.01.01.24\n",
    "suspect: 2003.11.24.01.11.24 - 2003.11.25.10.47.32\n",
    "imminent failure: 2003.11.25.10.57.32 - 2003.11.25.23.39.56\n",
    "\n",
    "Bearing 3\n",
    "early: 2003.10.22.12.06.24 - 2003.11.01.21.41.44\n",
    "normal: 2003.11.01.21.51.44 - 2003.11.22.09.16.56\n",
    "suspect: 2003.11.22.09.26.56 - 2003.11.25.10.47.32\n",
    "Inner race failure: 2003.11.25.10.57.32 - 2003.11.25.23.39.56\n",
    "\n",
    "Bearing 4\n",
    "early: 2003.10.22.12.06.24 - 2003.10.29.21.39.46\n",
    "normal: 2003.10.29.21.49.46 - 2003.11.15.05.08.46\n",
    "suspect: 2003.11.15.05.18.46 - 2003.11.18.19.12.30\n",
    "Rolling element failure: 2003.11.19.09.06.09 - 2003.11.22.17.36.56\n",
    "Stage 2 failure: 2003.11.22.17.46.56 - 2003.11.25.23.39.56\n",
    "\"\"\"\n",
    "\n",
    "def getAbsoluteTime(file):\n",
    "    #Subfunction for StateInformation\n",
    "    year   = int(file[0:4])\n",
    "    month  = int(file[5:7])\n",
    "    day    = int(file[8:10])\n",
    "    hour   = int(file[11:13])\n",
    "    minute = int(file[14:16])\n",
    "    second = int(file[17:19])\n",
    "    x = second + 60*minute + 60*60*hour + 24*60*60*day + 31*24*60*60*(month - 10)\n",
    "    return x\n",
    "\n",
    "def StateInformation(UserInput,BearingNum):\n",
    "    file = UserInput['File of Interest']\n",
    "    absolutetime = getAbsoluteTime(file)\n",
    "    #in seconds don't include years taking 10 as the start month\n",
    "    \n",
    "    #Bearing 1 transitions\n",
    "    b1e2s  = getAbsoluteTime(\"2013.10.23.09.14.13\")\n",
    "    b1s2n  = getAbsoluteTime(\"2003.11.08.12.11.44\")\n",
    "    b1n2s  = getAbsoluteTime(\"2003.11.19.21.06.07\")\n",
    "    b1s2i  = getAbsoluteTime(\"2003.11.24.20.47.32\")\n",
    "    \n",
    "    #Bearing 2 transitions\n",
    "    b2e2n  = getAbsoluteTime(\"2003.11.01.21.41.44\")\n",
    "    b2n2s  = getAbsoluteTime(\"2003.11.24.01.01.24\")\n",
    "    b2s2i  = getAbsoluteTime(\"2003.11.25.10.47.32\")\n",
    "    \n",
    "    #Bearing 3 transitions\n",
    "    b3e2n  = getAbsoluteTime(\"2003.11.01.21.41.44\")\n",
    "    b3n2s  = getAbsoluteTime(\"2003.11.22.09.16.56\")\n",
    "    b3s2irf  = getAbsoluteTime(\"2003.11.25.10.47.32\")\n",
    "    \n",
    "    #Bearing 4 transitions\n",
    "    b4e2n  = getAbsoluteTime(\"2003.10.29.21.39.46\")\n",
    "    b4n2s  = getAbsoluteTime(\"2003.11.15.05.08.46\")\n",
    "    b4s2r  = getAbsoluteTime(\"2003.11.18.19.12.30\")\n",
    "    b4r2f  = getAbsoluteTime(\"2003.11.22.17.36.56\")\n",
    "    \n",
    "    m = \"ERROR\"\n",
    "    if BearingNum == 1:\n",
    "        if absolutetime   <= b1e2s:\n",
    "            m = \"Early\"\n",
    "        elif absolutetime <= b1s2n:\n",
    "            m = \"Suspect\"\n",
    "        elif absolutetime <= b1n2s:\n",
    "            m = \"Normal\"\n",
    "        elif absolutetime <= b1s2i:\n",
    "            m = \"Suspect\"\n",
    "        elif absolutetime > b1s2i:\n",
    "            m = \"Imminent Failure\"\n",
    "    elif BearingNum == 2:\n",
    "        if absolutetime   <= b2e2n:\n",
    "            m = \"Early\"\n",
    "        elif absolutetime <= b2n2s:\n",
    "            m = \"Normal\"\n",
    "        elif absolutetime <= b2s2i:\n",
    "            m = \"Suspect\"\n",
    "        elif absolutetime > b2s2i:\n",
    "            m = \"Imminent Failure\" \n",
    "    elif BearingNum == 3:\n",
    "        if absolutetime   <= b3e2n:\n",
    "            m = \"Early\"\n",
    "        elif absolutetime <= b3n2s:\n",
    "            m = \"Normal\"\n",
    "        elif absolutetime <= b3s2irf:\n",
    "            m = \"Suspect\"\n",
    "        elif absolutetime >= b3s2irf:\n",
    "            m = \"Inner Race Failure\"   \n",
    "    elif BearingNum == 4:\n",
    "        if absolutetime   <= b4e2n:\n",
    "            m = \"Early\"\n",
    "        elif absolutetime <= b4n2s:\n",
    "            m = \"Normal\"\n",
    "        elif absolutetime <= b4s2r:\n",
    "            m = \"Suspect\"\n",
    "        elif absolutetime <= b4r2f:\n",
    "            m = \"Rolling Element Failure\"\n",
    "        elif absolutetime > b4r2f:\n",
    "            m = \"Stage 2 Failure\"\n",
    "    else:\n",
    "        m = \"ERROR\"\n",
    "        \n",
    "    x = {\n",
    "        \"State\": m\n",
    "    }\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MotorInformation(UserInput):\n",
    "    x = {\n",
    "        \"Motor Type AC(1)-DC(0)\": 1,\n",
    "        \"Shaft Speed [Hz]\": 2000/60\n",
    "    }\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCompleteDataFrame(UserInput,BearingNum):\n",
    "    UserInput1 = UserInput\n",
    "    UserInput1 = RemoveDCOffset(UserInput1)\n",
    "    BearingInfo = BearingInfomation(UserInput1)\n",
    "    TimeDomainInfo = TimeDomainInformation(UserInput1)\n",
    "    FrequecyDomainInfo = FrequencyDomainInformation(UserInput1)\n",
    "    StateInfo = StateInformation(UserInput1,BearingNum)\n",
    "    MotorInfo = MotorInformation(UserInput1)\n",
    "    Features = {**StateInfo,**MotorInfo,**BearingInfo,**TimeDomainInfo,**FrequecyDomainInfo}\n",
    "    Features = pd.DataFrame(Features, index=[0])\n",
    "    return Features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTESTDataFrame(UserInput):\n",
    "    UserInput1 = UserInput\n",
    "    UserInput1 = RemoveDCOffset(UserInput1)\n",
    "    BearingInfo = BearingInfomation(UserInput1)\n",
    "    TimeDomainInfo = TimeDomainInformation(UserInput1)\n",
    "    FrequecyDomainInfo = FrequencyDomainInformation(UserInput1)\n",
    "    MotorInfo = MotorInformation(UserInput1)\n",
    "    Features = {**MotorInfo,**BearingInfo,**TimeDomainInfo,**FrequecyDomainInfo}\n",
    "    Features = pd.DataFrame(Features, index=[0])\n",
    "    return Features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPlot(X,Y,xlabel,ylabel,Title):\n",
    "    #Subfunction of getGraphs\n",
    "    fig = plt.figure()\n",
    "    plt.plot(X,Y,c = np.random.rand(3,))\n",
    "    plt.xlabel(xlabel, fontsize=12)\n",
    "    plt.ylabel(ylabel, fontsize=12)\n",
    "    plt.title(Title)\n",
    "    plt.grid(True)\n",
    "    return fig\n",
    "\n",
    "def getGraphs(UserInput):\n",
    "    t = np.arange(0,UserInput['Time of Sampling'],1/UserInput['Sampling Frequency'])\n",
    "    figs = []\n",
    "    x1 = FourierTransform(UserInput)\n",
    "    x2 = get_psd_values(UserInput)\n",
    "    x3 = get_autocorr_values(UserInput)\n",
    "    UserInput1 = RemoveDCOffset(UserInput)\n",
    "    figs.append(getPlot(t,UserInput['Signal Data of Interest'],\"time (s)\",\"Amplitude\",\"Raw Data\"))\n",
    "    figs.append(getPlot(t,UserInput1['Signal Data of Interest'],\"time (s)\",\"Amplitude\",\"Raw Data w/ Removed DC Offset\"))\n",
    "    figs.append(getPlot(x1['Frequency'],x1['Freq. Amp.'],'Frequency [Hz]',\"time (s)\",\"FFT\"))\n",
    "    figs.append(getPlot(x2['Frequency'],x2['PSD'],'Frequency [Hz]','PSD [V**2 / Hz]',\"PSD\"))\n",
    "    figs.append(getPlot(x3['X Values'],x3['Autocorr Values'],'time delay [s]',\"Autocorrelation amplitude\",\"Autocorrelation\"))\n",
    "\n",
    "    return figs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getBarPlot(X,Y,xlabel,Title):\n",
    "    #Subfunction of getGraphs\n",
    "    fig = plt.figure()\n",
    "    y_pos = np.arange(len(Y))\n",
    "    plt.barh(y_pos, X, align='center')\n",
    "    plt.xlabel(xlabel, fontsize=12)\n",
    "    plt.yticks(y_pos, Y)\n",
    "    plt.title(Title)\n",
    "    plt.grid(True)\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetData(FileOfInterest):\n",
    "    #Subfunction for UserInputs2WorkingForm\n",
    "    data = pd.read_table(FileOfInterest,header = None)\n",
    "    data.columns = ['b1x','b1y','b2x','b2y','b3x','b3y','b4x','b4y']\n",
    "    return np.transpose(data.values[:,0])\n",
    "\n",
    "def UserInputs2WorkingForm(n,N,Bd,Pd,phi,SampleFrequency,FileOfInterest,\\\n",
    "                           HomeDirectory,directory,TrainingDataFile):\n",
    "    sig = GetData(FileOfInterest)\n",
    "    NumberOfSamples = len(sig)\n",
    "    dt = 1/SampleFrequency\n",
    "    Tmax = dt*NumberOfSamples\n",
    "    x = {\n",
    "        'n': n, #Shaft rotational speed [Hz], n\n",
    "        'N': N, #No. of rolling elements [-], N\n",
    "        'Bd': Bd, #Diameter of a rolling element [mm], Bd\n",
    "        'Pd': Pd, #Pitch diameter [mm], Pd\n",
    "        'Phi': phi, #Contact angle [rad], Phi\n",
    "        'Sampling Frequency': SampleFrequency,\n",
    "        'Time of Sampling': Tmax,\n",
    "        'Number of Samples': NumberOfSamples,\n",
    "        'File of Interest': FileOfInterest,\n",
    "        'HomeDirectory': HomeDirectory,\n",
    "        'Working Directory': directory,\n",
    "        'TrainingFileName': TrainingDataFile,\n",
    "        'Signal Data of Interest': sig    \n",
    "    }\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def truncate(f, n):\n",
    "    '''https://stackoverflow.com/questions/783897/truncating-floats-in-python/51172324#51172324'''\n",
    "    '''Truncates/pads a float f to n decimal places without rounding'''\n",
    "    s = '{}'.format(f)\n",
    "    if 'e' in s or 'E' in s:\n",
    "        return '{0:.{1}f}'.format(f, n)\n",
    "    i, p, d = s.partition('.')\n",
    "    return '.'.join([i, (d+'0'*n)[:n]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetTrainingData(UserInput):\n",
    "    for file in UserInput['Working Directory']:\n",
    "        if file == UserInput['TrainingFileName']:\n",
    "            dataset = pd.read_csv(file,header = 0,index_col = 0)\n",
    "\n",
    "    X = dataset.values[:,1:(dataset.shape[1]-1)]\n",
    "    Y = dataset.values[:,0]\n",
    "    validation_size = 0.20\n",
    "    seed = 6\n",
    "    X_train, X_test, Y_train, Y_test = model_selection.train_test_split(X, Y, test_size=validation_size, random_state=seed) \n",
    "    \n",
    "    return X_train, X_test, Y_train, Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetTrainingData2(UserInput):\n",
    "    for file in UserInput['Working Directory']:\n",
    "        if file == UserInput['TrainingFileName']:\n",
    "            dataset = pd.read_csv(file,header = 0,index_col = 0)\n",
    "\n",
    "    X = dataset.values[:,1:(dataset.shape[1]-1)]\n",
    "    Y = dataset.values[:,0]\n",
    "    validation_size = 0.20\n",
    "    seed = 21\n",
    "    X_train, X_test, Y_train, Y_test = model_selection.train_test_split(X, Y, test_size=validation_size, random_state=seed) \n",
    "    \n",
    "    return X_train, X_test, Y_train, Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetTESTDataFrameNames(UserInput):\n",
    "    for file in UserInput['Working Directory']:\n",
    "        if file == UserInput['TrainingFileName']:\n",
    "            dataset = pd.read_csv(file,header = 0,index_col = 0)\n",
    "    names = []\n",
    "    for x in dataset.columns:\n",
    "        names.append(x)\n",
    "    return names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TrainModel(X_train,Y_train):\n",
    "    classifier = RandomForestClassifier(n_estimators=1000)\n",
    "    classifier = classifier.fit(X_train, Y_train)\n",
    "    return classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PredictModel(classifier,X_test):\n",
    "    Y_test_pred = classifier.predict(X_test)\n",
    "    return Y_test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetAllModelsForComparison(X_train,Y_train):\n",
    "    models = {\n",
    "        'ARDRegression': ARDRegression(),\n",
    "        'BayesianRidge': BayesianRidge(),\n",
    "        'ElasticNet': ElasticNet(),\n",
    "        'ElasticNetCV': ElasticNetCV(),\n",
    "        'Hinge': Hinge(),\n",
    "        'Huber': Huber(),\n",
    "        'HuberRegressor': HuberRegressor(),\n",
    "        'Lars': Lars(),\n",
    "        'LarsCV': LarsCV(),\n",
    "        'Lasso': Lasso(),\n",
    "        'LassoCV': LassoCV(),\n",
    "        'LassoLars': LassoLars(),\n",
    "        'LassoLarsCV': LassoLarsCV(),\n",
    "        'LinearRegression': LinearRegression(),\n",
    "        'Log': Log(),\n",
    "        'LogisticRegression': LogisticRegression(),\n",
    "        'LogisticRegressionCV': LogisticRegressionCV(),\n",
    "        'ModifiedHuber': ModifiedHuber(),\n",
    "        'MultiTaskElasticNet': MultiTaskElasticNet(),\n",
    "        'MultiTaskElasticNetCV': MultiTaskElasticNetCV(),\n",
    "        'MultiTaskLasso': MultiTaskLasso(),\n",
    "        'MultiTaskLassoCV': MultiTaskLassoCV(),\n",
    "        'OrthogonalMatchingPursuit': OrthogonalMatchingPursuit(),\n",
    "        'OrthogonalMatchingPursuitCV': OrthogonalMatchingPursuitCV(),\n",
    "        'PassiveAggressiveClassifier': PassiveAggressiveClassifier(),\n",
    "        'PassiveAggressiveRegressor': PassiveAggressiveRegressor(),\n",
    "        'Perceptron': Perceptron(),\n",
    "        'RANSACRegressor': RANSACRegressor(),\n",
    "        'RandomizedLasso': RandomizedLasso(),\n",
    "        'RandomizedLogisticRegression': RandomizedLogisticRegression(),\n",
    "        'Ridge': Ridge(),\n",
    "        'RidgeCV': RidgeCV(),\n",
    "        'RidgeClassifier': RidgeClassifier(),\n",
    "        'SGDClassifier': SGDClassifier(),\n",
    "        'SGDRegressor': SGDRegressor(),\n",
    "        'SquaredLoss': SquaredLoss(),\n",
    "        'TheilSenRegressor': TheilSenRegressor(),\n",
    "        'BaseEstimator': BaseEstimator(),\n",
    "        'ClassifierMixin': ClassifierMixin(),\n",
    "        'LinearClassifierMixin': LinearClassifierMixin(),\n",
    "        'LinearDiscriminantAnalysis': LinearDiscriminantAnalysis(),\n",
    "        'QuadraticDiscriminantAnalysis': QuadraticDiscriminantAnalysis(),\n",
    "        'StandardScaler': StandardScaler(),\n",
    "        'TransformerMixin': TransformerMixin(),\n",
    "        'BaseEstimator': BaseEstimator(),\n",
    "        'KernelRidge': KernelRidge(),\n",
    "        'RegressorMixin': RegressorMixin(),\n",
    "        'LinearSVC': LinearSVC(),\n",
    "        'LinearSVR': LinearSVR(),\n",
    "        'NuSVC': NuSVC(),\n",
    "        'NuSVR': NuSVR(),\n",
    "        'OneClassSVM': OneClassSVM(),\n",
    "        'SVC': SVC(),\n",
    "        'SVR': SVR(),\n",
    "        'SGDClassifier': SGDClassifier(),\n",
    "        'SGDRegressor': SGDRegressor(),\n",
    "        'BallTree': BallTree(),\n",
    "        'DistanceMetric': DistanceMetric(),\n",
    "        'KDTree': KDTree(),\n",
    "        'KNeighborsClassifier': KNeighborsClassifier(),\n",
    "        'KNeighborsRegressor': KNeighborsRegressor(),\n",
    "        'KernelDensity': KernelDensity(),\n",
    "        'LSHForest': LSHForest(),\n",
    "        'LocalOutlierFactor': LocalOutlierFactor(),\n",
    "        'NearestCentroid': NearestCentroid(),\n",
    "        'NearestNeighbors': NearestNeighbors(),\n",
    "        'RadiusNeighborsClassifier': RadiusNeighborsClassifier(),\n",
    "        'RadiusNeighborsRegressor': RadiusNeighborsRegressor(),\n",
    "        'GaussianProcess': GaussianProcess(),\n",
    "        'GaussianProcessRegressor': GaussianProcessRegressor(),\n",
    "        'GaussianProcessClassifier': GaussianProcessClassifier(),\n",
    "        'CCA': CCA(),\n",
    "        'PLSCanonical': PLSCanonical(),\n",
    "        'PLSRegression': PLSRegression(),\n",
    "        'PLSSVD': PLSSVD(),\n",
    "        'ABCMeta': ABCMeta(),\n",
    "        'BaseDiscreteNB': BaseDiscreteNB(),\n",
    "        'BaseEstimator': BaseEstimator(),\n",
    "        'BaseNB': BaseNB(),\n",
    "        'BernoulliNB': BernoulliNB(),\n",
    "        'ClassifierMixin': ClassifierMixin(),\n",
    "        'GaussianNB': GaussianNB(),\n",
    "        'LabelBinarizer': LabelBinarizer(),\n",
    "        'MultinomialNB': MultinomialNB(),\n",
    "        'DecisionTreeClassifier': DecisionTreeClassifier(),\n",
    "        'DecisionTreeRegressor': DecisionTreeRegressor(),\n",
    "        'ExtraTreeClassifier': ExtraTreeClassifier(),\n",
    "        'AdaBoostClassifier': AdaBoostClassifier(),\n",
    "        'AdaBoostRegressor': AdaBoostRegressor(),\n",
    "        'BaggingClassifier': BaggingClassifier(),\n",
    "        'BaggingRegressor': BaggingRegressor(),\n",
    "        'BaseEnsemble': BaseEnsemble(),\n",
    "        'ExtraTreesClassifier': ExtraTreesClassifier(),\n",
    "        'ExtraTreesRegressor': ExtraTreesRegressor(),\n",
    "        'GradientBoostingClassifier': GradientBoostingClassifier(),\n",
    "        'GradientBoostingRegressor': GradientBoostingRegressor(),\n",
    "        'IsolationForest': IsolationForest(),\n",
    "        'RandomForestClassifier': RandomForestClassifier(),\n",
    "        'RandomForestRegressor': RandomForestRegressor(),\n",
    "        'RandomTreesEmbedding': RandomTreesEmbedding(),\n",
    "        'VotingClassifier': VotingClassifier(),\n",
    "        'BaseEstimator': BaseEstimator(),\n",
    "        'ClassifierMixin': ClassifierMixin(),\n",
    "        'LabelBinarizer': LabelBinarizer(),\n",
    "        'MetaEstimatorMixin': MetaEstimatorMixin(),\n",
    "        'OneVsOneClassifier': OneVsOneClassifier(),\n",
    "        'OneVsRestClassifier': OneVsRestClassifier(),\n",
    "        'OutputCodeClassifier': OutputCodeClassifier(),\n",
    "        'Parallel': Parallel(),\n",
    "        'ABCMeta': ABCMeta(),\n",
    "        'BaseEstimator': BaseEstimator(),\n",
    "        'ClassifierChain': ClassifierChain(),\n",
    "        'ClassifierMixin': ClassifierMixin(),\n",
    "        'MetaEstimatorMixin': MetaEstimatorMixin(),\n",
    "        'MultiOutputClassifier': MultiOutputClassifier(),\n",
    "        'MultiOutputEstimator': MultiOutputEstimator(),\n",
    "        'MultiOutputRegressor': MultiOutputRegressor(),\n",
    "        'Parallel': Parallel(),\n",
    "        'RegressorMixin': RegressorMixin(),\n",
    "        'LabelPropagation': LabelPropagation(),\n",
    "        'LabelSpreading': LabelSpreading(),\n",
    "        'BaseEstimator': BaseEstimator(),\n",
    "        'IsotonicRegression': IsotonicRegression(),\n",
    "        'RegressorMixin': RegressorMixin(),\n",
    "        'TransformerMixin': TransformerMixin(),\n",
    "        'BernoulliRBM': BernoulliRBM(),\n",
    "        'MLPClassifier': MLPClassifier(),\n",
    "        'MLPRegressor': MLPRegressor()\n",
    "        }\n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetUserInputNames(UserInput):\n",
    "    names = []\n",
    "    for x in UserInput:\n",
    "        names.append(x)\n",
    "    return names"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
